package qingying

import (
	"context"
	"fmt"
	"io"
	"net/http"
	"net/url"
	"regexp"
	"strings"
	"sync"
	"time"

	"github.com/PuerkitoBio/goquery"
	"pansou/model"
	"pansou/plugin"
)

const (
	baseURL       = "http://revohd.com"
	searchPath    = "/vodsearch/-------------.html"
	maxResults    = 10
	maxConcurrent = 3
)

var debugMode = false

func debugPrintf(format string, args ...interface{}) {
	if debugMode {
		fmt.Printf("[QingYing DEBUG] "+format, args...)
	}
}

type QingYingPlugin struct {
	*plugin.BaseAsyncPlugin
}

func init() {
	p := &QingYingPlugin{
		BaseAsyncPlugin: plugin.NewBaseAsyncPlugin("qingying", 3),
	}
	plugin.RegisterGlobalPlugin(p)
}

func (p *QingYingPlugin) Search(keyword string, ext map[string]interface{}) ([]model.SearchResult, error) {
	result, err := p.SearchWithResult(keyword, ext)
	if err != nil {
		return nil, err
	}
	return result.Results, nil
}

func (p *QingYingPlugin) SearchWithResult(keyword string, ext map[string]interface{}) (model.PluginSearchResult, error) {
	return p.AsyncSearchWithResult(keyword, p.searchImpl, p.MainCacheKey, ext)
}

func (p *QingYingPlugin) searchImpl(client *http.Client, keyword string, ext map[string]interface{}) ([]model.SearchResult, error) {
	debugPrintf("ğŸ” å¼€å§‹æœç´¢ - keyword: %s\n", keyword)
	searchURL := fmt.Sprintf("%s%s?wd=%s", baseURL, searchPath, url.QueryEscape(keyword))
	debugPrintf("ğŸ“ æœç´¢URL: %s\n", searchURL)
	
	items, err := p.fetchSearchResults(searchURL, client)
	if err != nil {
		debugPrintf("âŒ è·å–æœç´¢ç»“æœå¤±è´¥: %v\n", err)
		return nil, err
	}
	
	debugPrintf("âœ… è·å–åˆ° %d ä¸ªæœç´¢ç»“æœ\n", len(items))
	
	if len(items) == 0 {
		debugPrintf("âš ï¸ æ²¡æœ‰æœç´¢ç»“æœ\n")
		return []model.SearchResult{}, nil
	}
	
	filteredItems := p.filterItemsByKeyword(items, keyword)
	debugPrintf("ğŸ” æ ‡é¢˜è¿‡æ»¤åå‰©ä½™ %d ä¸ªç»“æœï¼ˆä» %d ä¸ªï¼‰\n", len(filteredItems), len(items))
	
	if len(filteredItems) == 0 {
		debugPrintf("âš ï¸ æ ‡é¢˜è¿‡æ»¤åæ²¡æœ‰åŒ¹é…çš„ç»“æœ\n")
		return []model.SearchResult{}, nil
	}
	
	if len(filteredItems) > maxResults {
		debugPrintf("âœ‚ï¸ é™åˆ¶ç»“æœæ•°é‡ä» %d åˆ° %d\n", len(filteredItems), maxResults)
		filteredItems = filteredItems[:maxResults]
	}
	
	results := p.processDetailPages(filteredItems, client)
	debugPrintf("ğŸ“Š å¤„ç†å®Œæˆï¼Œè·å¾— %d ä¸ªæœ‰æ•ˆç»“æœ\n", len(results))
	
	return results, nil
}

type searchItem struct {
	ID        string
	Title     string
	DetailURL string
}

func (p *QingYingPlugin) filterItemsByKeyword(items []searchItem, keyword string) []searchItem {
	lowerKeyword := strings.ToLower(keyword)
	var filtered []searchItem
	
	for _, item := range items {
		lowerTitle := strings.ToLower(item.Title)
		if strings.Contains(lowerTitle, lowerKeyword) {
			debugPrintf("âœ… æ ‡é¢˜åŒ¹é…: %s\n", item.Title)
			filtered = append(filtered, item)
		} else {
			debugPrintf("âŒ æ ‡é¢˜ä¸åŒ¹é…ï¼Œè·³è¿‡: %s\n", item.Title)
		}
	}
	
	return filtered
}

func (p *QingYingPlugin) fetchSearchResults(searchURL string, client *http.Client) ([]searchItem, error) {
	debugPrintf("ğŸŒ è¯·æ±‚æœç´¢é¡µé¢: %s\n", searchURL)
	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()
	
	req, err := http.NewRequestWithContext(ctx, "GET", searchURL, nil)
	if err != nil {
		return nil, fmt.Errorf("[%s] åˆ›å»ºè¯·æ±‚å¤±è´¥: %w", p.Name(), err)
	}
	
	p.setHeaders(req, baseURL)
	
	resp, err := p.doRequestWithRetry(req, client)
	if err != nil {
		return nil, fmt.Errorf("[%s] æœç´¢è¯·æ±‚å¤±è´¥: %w", p.Name(), err)
	}
	defer resp.Body.Close()
	
	debugPrintf("ğŸ“¡ HTTPçŠ¶æ€ç : %d\n", resp.StatusCode)
	
	if resp.StatusCode != 200 {
		return nil, fmt.Errorf("[%s] è¯·æ±‚è¿”å›çŠ¶æ€ç : %d", p.Name(), resp.StatusCode)
	}
	
	doc, err := goquery.NewDocumentFromReader(resp.Body)
	if err != nil {
		return nil, fmt.Errorf("[%s] HTMLè§£æå¤±è´¥: %w", p.Name(), err)
	}
	
	var items []searchItem
	doc.Find("div.module-search-item").Each(func(i int, s *goquery.Selection) {
		link := s.Find(".video-info .video-info-header h3 a")
		href, exists := link.Attr("href")
		if !exists {
			debugPrintf("âš ï¸ ç¬¬%dä¸ªç»“æœæ²¡æœ‰hrefå±æ€§\n", i+1)
			return
		}
		
		title := strings.TrimSpace(link.Text())
		if title == "" {
			title, _ = link.Attr("title")
			title = strings.TrimSpace(title)
		}
		
		if title == "" {
			debugPrintf("âš ï¸ ç¬¬%dä¸ªç»“æœæ ‡é¢˜ä¸ºç©º\n", i+1)
			return
		}
		
		re := regexp.MustCompile(`/voddetail/(\d+)\.html`)
		matches := re.FindStringSubmatch(href)
		if len(matches) < 2 {
			debugPrintf("âš ï¸ æ— æ³•ä»hrefæå–ID: %s\n", href)
			return
		}
		
		item := searchItem{
			ID:        matches[1],
			Title:     title,
			DetailURL: p.buildAbsURL(href),
		}
		debugPrintf("ğŸ“Œ æ‰¾åˆ°å½±ç‰‡: ID=%s, Title=%s\n", item.ID, item.Title)
		items = append(items, item)
	})
	
	debugPrintf("âœ… è§£æåˆ° %d ä¸ªæœç´¢é¡¹\n", len(items))
	return items, nil
}

func (p *QingYingPlugin) processDetailPages(items []searchItem, client *http.Client) []model.SearchResult {
	var results []model.SearchResult
	var mu sync.Mutex
	var wg sync.WaitGroup
	sem := make(chan struct{}, maxConcurrent)
	
	for _, item := range items {
		wg.Add(1)
		go func(it searchItem) {
			defer wg.Done()
			sem <- struct{}{}
			defer func() { <-sem }()
			
			result := p.processDetailPage(it, client)
			if result != nil {
				mu.Lock()
				results = append(results, *result)
				mu.Unlock()
			}
		}(item)
	}
	
	wg.Wait()
	return results
}

func (p *QingYingPlugin) processDetailPage(item searchItem, client *http.Client) *model.SearchResult {
	debugPrintf("ğŸ¬ å¤„ç†è¯¦æƒ…é¡µ: %s (ID: %s)\n", item.Title, item.ID)
	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()
	
	req, err := http.NewRequestWithContext(ctx, "GET", item.DetailURL, nil)
	if err != nil {
		debugPrintf("âŒ åˆ›å»ºè¯·æ±‚å¤±è´¥: %v\n", err)
		return nil
	}
	
	p.setHeaders(req, baseURL)
	
	resp, err := p.doRequestWithRetry(req, client)
	if err != nil {
		debugPrintf("âŒ è¯¦æƒ…é¡µè¯·æ±‚å¤±è´¥: %v\n", err)
		return nil
	}
	defer resp.Body.Close()
	
	if resp.StatusCode != 200 {
		debugPrintf("âŒ è¯¦æƒ…é¡µçŠ¶æ€ç : %d\n", resp.StatusCode)
		return nil
	}
	
	body, err := io.ReadAll(resp.Body)
	if err != nil {
		debugPrintf("âŒ è¯»å–å“åº”å¤±è´¥: %v\n", err)
		return nil
	}
	
	doc, err := goquery.NewDocumentFromReader(strings.NewReader(string(body)))
	if err != nil {
		debugPrintf("âŒ HTMLè§£æå¤±è´¥: %v\n", err)
		return nil
	}
	
	title := strings.TrimSpace(doc.Find(".video-info .video-info-header h1.page-title a").Text())
	if title == "" {
		title = item.Title
	}
	debugPrintf("ğŸ“ å½±ç‰‡æ ‡é¢˜: %s\n", title)
	
	var description string
	var updateTime time.Time
	doc.Find(".video-info-items").Each(func(i int, s *goquery.Selection) {
		itemTitle := strings.TrimSpace(s.Find(".video-info-itemtitle").Text())
		
		if strings.Contains(itemTitle, "æ›´æ–°") {
			timeText := strings.TrimSpace(s.Find(".video-info-item").Text())
			debugPrintf("ğŸ• æ‰¾åˆ°æ›´æ–°æ—¶é—´æ–‡æœ¬: %s\n", timeText)
			updateTime = p.parseUpdateTimeFromHTML(timeText)
			if !updateTime.IsZero() {
				debugPrintf("âœ… è§£ææ›´æ–°æ—¶é—´æˆåŠŸ: %v\n", updateTime)
			}
		}
		
		if strings.Contains(itemTitle, "å‰§æƒ…") {
			content := s.Find(".video-info-item.video-info-content span")
			if content.Length() > 0 {
				description = strings.TrimSpace(content.Text())
			} else {
				description = strings.TrimSpace(s.Find(".video-info-item").Text())
			}
			if len(description) > 50 {
				debugPrintf("ğŸ“– å‰§æƒ…ç®€ä»‹: %s...\n", description[:50])
			} else {
				debugPrintf("ğŸ“– å‰§æƒ…ç®€ä»‹: %s\n", description)
			}
		}
	})
	
	if updateTime.IsZero() {
		updateTime = time.Now()
		debugPrintf("âš ï¸ æœªæ‰¾åˆ°æ›´æ–°æ—¶é—´ï¼Œä½¿ç”¨å½“å‰æ—¶é—´\n")
	}
	
	panLink := p.extract123PanLink(doc)
	if panLink == nil {
		debugPrintf("âŒ æœªæ‰¾åˆ°123ç½‘ç›˜é“¾æ¥\n")
		return nil
	}
	
	debugPrintf("âœ… æ‰¾åˆ°123ç½‘ç›˜é“¾æ¥: %s (å¯†ç : %s)\n", panLink.URL, panLink.Password)
	
	return &model.SearchResult{
		UniqueID: fmt.Sprintf("%s-%s", p.Name(), item.ID),
		Title:    title,
		Content:  description,
		Links:    []model.Link{*panLink},
		Channel:  "",
		Datetime: updateTime,
	}
}

func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}

func (p *QingYingPlugin) extract123PanLink(doc *goquery.Document) *model.Link {
	debugPrintf("ğŸ” å¼€å§‹æå–123ç½‘ç›˜é“¾æ¥\n")
	var panURL string
	
	found := false
	doc.Find(".module-heading h2.module-title").Each(func(i int, s *goquery.Selection) {
		text := strings.TrimSpace(s.Text())
		debugPrintf("ğŸ“‹ æ‰¾åˆ°æ ‡é¢˜: %s\n", text)
		if strings.Contains(text, "123") && strings.Contains(text, "äº‘ç›˜") {
			found = true
			debugPrintf("âœ… åŒ¹é…åˆ°123äº‘ç›˜æ ‡é¢˜\n")
		}
	})
	
	if !found {
		debugPrintf("âŒ æœªæ‰¾åˆ°123äº‘ç›˜æ ‡é¢˜åŒºåŸŸ\n")
		return nil
	}
	
	doc.Find(".module-downlist .module-row-text").Each(func(i int, s *goquery.Selection) {
		if panURL != "" {
			return
		}
		
		clipboardText, exists := s.Attr("data-clipboard-text")
		debugPrintf("ğŸ”— æ£€æŸ¥é“¾æ¥ #%d: exists=%v, text=%s\n", i+1, exists, clipboardText)
		if exists {
			url := strings.TrimSpace(clipboardText)
			if strings.Contains(url, "123684.com") || strings.Contains(url, "123685.com") || 
			   strings.Contains(url, "123912.com") || strings.Contains(url, "123pan.com") ||
			   strings.Contains(url, "123pan.cn") || strings.Contains(url, "123592.com") {
				panURL = url
				debugPrintf("âœ… æ‰¾åˆ°123ç½‘ç›˜é“¾æ¥: %s\n", panURL)
			}
		}
	})
	
	if panURL == "" {
		debugPrintf("âŒ æœªæ‰¾åˆ°123ç½‘ç›˜é“¾æ¥\n")
		return nil
	}
	
	password := p.extractPassword(panURL)
	debugPrintf("ğŸ”‘ æå–å¯†ç : %s\n", password)
	
	return &model.Link{
		Type:     "123",
		URL:      panURL,
		Password: password,
	}
}

func (p *QingYingPlugin) parseUpdateTimeFromHTML(timeText string) time.Time {
	re := regexp.MustCompile(`(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})`)
	matches := re.FindStringSubmatch(timeText)
	if len(matches) < 2 {
		debugPrintf("âŒ æ— æ³•ä»æ–‡æœ¬æå–æ—¶é—´: %s\n", timeText)
		return time.Time{}
	}
	
	timeStr := strings.TrimSpace(matches[1])
	debugPrintf("ğŸ” æå–åˆ°æ—¶é—´å­—ç¬¦ä¸²: %s\n", timeStr)
	
	t, err := time.ParseInLocation("2006-01-02 15:04:05", timeStr, time.Local)
	if err != nil {
		debugPrintf("âŒ æ—¶é—´è§£æå¤±è´¥: %v\n", err)
		return time.Time{}
	}
	
	return t
}

func (p *QingYingPlugin) extractPassword(panURL string) string {
	parsed, err := url.Parse(panURL)
	if err != nil {
		return ""
	}
	
	pwd := parsed.Query().Get("pwd")
	if pwd != "" && len(pwd) == 4 {
		return pwd
	}
	
	pwdRegex := regexp.MustCompile(`pwd=([a-zA-Z0-9]{4})`)
	if matches := pwdRegex.FindStringSubmatch(panURL); len(matches) > 1 {
		return matches[1]
	}
	
	return ""
}

func (p *QingYingPlugin) buildAbsURL(path string) string {
	if strings.HasPrefix(path, "http://") || strings.HasPrefix(path, "https://") {
		return path
	}
	if strings.HasPrefix(path, "//") {
		return "https:" + path
	}
	if !strings.HasPrefix(path, "/") {
		path = "/" + path
	}
	return baseURL + path
}

func (p *QingYingPlugin) setHeaders(req *http.Request, referer string) {
	req.Header.Set("User-Agent", "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")
	req.Header.Set("Accept", "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8")
	req.Header.Set("Accept-Language", "zh-CN,zh;q=0.9,en;q=0.8")
	req.Header.Set("Connection", "keep-alive")
	req.Header.Set("Referer", referer)
}

func (p *QingYingPlugin) doRequestWithRetry(req *http.Request, client *http.Client) (*http.Response, error) {
	maxRetries := 3
	var lastErr error
	
	for i := 0; i < maxRetries; i++ {
		if i > 0 {
			backoff := time.Duration(1<<uint(i-1)) * 200 * time.Millisecond
			time.Sleep(backoff)
		}
		
		reqClone := req.Clone(req.Context())
		resp, err := client.Do(reqClone)
		if err == nil && resp.StatusCode == 200 {
			return resp, nil
		}
		
		if resp != nil {
			resp.Body.Close()
		}
		lastErr = err
	}
	
	return nil, fmt.Errorf("é‡è¯• %d æ¬¡åä»ç„¶å¤±è´¥: %w", maxRetries, lastErr)
}
